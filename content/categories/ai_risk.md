---
id: ai-risk
name: 'AI Existential Risk'
costPerLife: 25
---

# Justification of cost per life

Assume that with out past spending of roughly a billion dollars on AI safety we've reduced existential risk by about 1%. Assume the marginal value of the next dollars in this area is the same
as with the first billion.

Then spending a billion more dollars has a 1% chance of saving 8 billion people, which is 80 million lives in expected value. Each person's life is on average half over, so cut that to 40
million lives for a billion dollars, or $25 per life.

Disagree? This project hasn't officially launched yet and we're looking for help improving our cost per life estimates.
If you'd like to contribute, read about how you can do so [here](https://github.com/impactlist/impactlist/blob/master/CONTRIBUTING.md).

# Internal Notes

https://80000hours.org/articles/existential-risks/ argues the cost is about $1000, but maybe $100, counting existing people

We've already spent between 600 million and a billion dollars on AI safety. Assume we've reduced xrisk by 1%. Assume the marginal value of the next billion is the same.

So 1 billion --> 1% chance of saving 8 billion people --> 80 million lives in EV... but each person's life is already half over, so 40 million lives for a billion, or $25 per life.

Note that this assumes that in a good AI future our longevity is not increased at all -- everyone just lives a normally long life, of equal quality to their life now.
But in reality a good AGI outcome would likely significantly extend our lives, possibly up to a trillion years or more.

If people lived a million years on average after a good AGI outcome, then that multiplies the lives by 12500, $25/12500 = $0.002

Each person lives a billion years --> $0.000002
