---
id: anthropic
name: 'Anthropic'
categories:
  - id: ai-capabilities
    fraction: 1
    effects:
      - effectId: population-late
        multipliers:
          costPerMicroprobability: 4
---

# Notes

Anthropic seems to be racing toward AGI, but
they appear more safety focused than most AI capabilities organizations so we'll provisionally give them a high multiplier (since their effect is negative, a high multiplier makes them less harmful rather than less helpful as it would for most charities).

Disagree? This project hasn't launched yet and we're looking for help improving our cost per life estimates.
If you'd like to contribute, read about how you can do so [here](https://github.com/impactlist/impactlist/blob/master/CONTRIBUTING.md).
